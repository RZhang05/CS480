{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import imageio.v3 as imageio\n",
    "import albumentations as A\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "import torchmetrics\n",
    "import time\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    IMAGE_SIZE = 384\n",
    "    BACKBONE = 'swin_large_patch4_window12_384.ms_in22k_ft_in1k'\n",
    "    TARGET_COLUMNS = ['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean']\n",
    "    N_TARGETS = len(TARGET_COLUMNS)\n",
    "    BATCH_SIZE = 10\n",
    "    LR_MAX = 1e-4\n",
    "    WEIGHT_DECAY = 0.01\n",
    "    N_EPOCHS = 6\n",
    "    TRAIN_MODEL = True\n",
    "    Lower_Quantile = 0.005\n",
    "    Upper_Quantile = 0.985\n",
    "\n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, X_jpeg_bytes, X_tabular, y, transforms=None):\n",
    "        self.X_jpeg_bytes = X_jpeg_bytes\n",
    "        self.X_tabular = X_tabular\n",
    "        self.y = y\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X_sample = self.transforms(\n",
    "            image=imageio.imread(self.X_jpeg_bytes[index]),\n",
    "        )['image']\n",
    "        X_tabular_sample = self.X_tabular[index]\n",
    "        y_sample = self.y[index]\n",
    "\n",
    "        return X_sample, X_tabular_sample, y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularBackbone(nn.Module):\n",
    "    def __init__(self, n_features, out_features):\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(n_features, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.GELU(),\n",
    "            # nn.Dropout(0.1),\n",
    "            nn.Linear(512, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "class ImageBackbone(nn.Module):\n",
    "    def __init__(self, backbone_name, weight_path, out_features, fixed_feature_extractor=False):\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "        self.backbone = timm.create_model(backbone_name, pretrained=False, num_classes=CONFIG.N_TARGETS)\n",
    "        checkpoint = torch.load(weight_path).backbone\n",
    "        self.backbone.load_state_dict(checkpoint.state_dict())\n",
    "        if fixed_feature_extractor:\n",
    "            for param in self.backbone.parameters():\n",
    "                param.requires_grad = False\n",
    "        in_features = self.backbone.num_features\n",
    "        \n",
    "        self.backbone.head = nn.Identity()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        return self.head(x)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, img_backbone, tab_backbone, out_features:int):\n",
    "        super().__init__()\n",
    "        self.img_backbone = img_backbone\n",
    "        self.tab_backbone = tab_backbone\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.tab_backbone.out_features + self.img_backbone.out_features, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.GELU(),\n",
    "            # nn.Dropout(0.1),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.GELU(),\n",
    "            # nn.Dropout(0.1),\n",
    "            nn.Linear(256, out_features),\n",
    "        )\n",
    "\n",
    "    def forward(self, img, tab):\n",
    "        img_features = self.img_backbone(img)\n",
    "        tab_features = self.tab_backbone(tab)\n",
    "        features = torch.cat([img_features, tab_features], dim=1)\n",
    "        return self.fc(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val):\n",
    "        self.sum += val.sum()\n",
    "        self.count += val.numel()\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_scheduler(optimizer):\n",
    "    return torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer=optimizer,\n",
    "        max_lr=CONFIG.LR_MAX,\n",
    "        total_steps=CONFIG.N_STEPS,\n",
    "        pct_start=0.1,\n",
    "        anneal_strategy='cos',\n",
    "        div_factor=1e1,\n",
    "        final_div_factor=1e1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in CONFIG.TARGET_COLUMNS:\n",
    "    lower_quantile = train[column].quantile(CONFIG.Lower_Quantile)\n",
    "    upper_quantile = train[column].quantile(CONFIG.Upper_Quantile)\n",
    "    train = train[(train[column] >= lower_quantile) & (train[column] <= upper_quantile)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular = train.drop(columns = ['id'] + CONFIG.TARGET_COLUMNS)\n",
    "test_tabular = test.drop(columns = ['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FEATURES = ['X4_mean', 'X11_mean', 'X18_mean', 'X26_mean', 'X50_mean', 'X3112_mean']\n",
    "\n",
    "y_train = np.zeros_like(train[CONFIG.TARGET_COLUMNS], dtype=np.float32)\n",
    "for target_idx, target in enumerate(CONFIG.TARGET_COLUMNS):\n",
    "    v = train[target].values\n",
    "    if target in LOG_FEATURES:\n",
    "        v = np.log10(v)\n",
    "    y_train[:, target_idx] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize tabular inputs\n",
    "X_SCALER = StandardScaler()\n",
    "tabular_scaled = X_SCALER.fit_transform(tabular).astype(np.float32)\n",
    "test_tabular_scaled = X_SCALER.transform(test_tabular).astype(np.float32)\n",
    "\n",
    "Y_SCALER = StandardScaler()\n",
    "y_train_scaled = Y_SCALER.fit_transform(y_train).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG Files Processing:\n",
      "JPEG Files Processing End\n"
     ]
    }
   ],
   "source": [
    "print('JPEG Files Processing:')\n",
    "train['file_path'] = train['id'].apply(lambda s: f'./data/train_images/{s}.jpeg')\n",
    "train['jpeg_bytes'] = train['file_path'].apply(lambda fp: open(fp, 'rb').read())\n",
    "\n",
    "test['file_path'] = test['id'].apply(lambda s: f'./data/test_images/{s}.jpeg')\n",
    "test['jpeg_bytes'] = test['file_path'].apply(lambda fp: open(fp, 'rb').read())\n",
    "print('JPEG Files Processing End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG.N_TRAIN_SAMPLES = len(tabular_scaled)\n",
    "CONFIG.N_STEPS_PER_EPOCH = (CONFIG.N_TRAIN_SAMPLES // CONFIG.BATCH_SIZE)\n",
    "CONFIG.N_STEPS = CONFIG.N_STEPS_PER_EPOCH * CONFIG.N_EPOCHS + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "TRAIN_TRANSFORMS = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomSizedCrop(\n",
    "        [96, 128],\n",
    "        CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE, w2h_ratio=1.0, p=0.8),\n",
    "    A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.3),\n",
    "    A.ImageCompression(quality_lower=85, quality_upper=100, p=0.3),\n",
    "    A.ToFloat(),\n",
    "    A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "TEST_TRANSFORMS = A.Compose([\n",
    "    A.Resize(CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE),\n",
    "    A.ToFloat(),\n",
    "    A.Normalize(mean=MEAN, std=STD, max_pixel_value=1),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# train / test split\n",
    "train_idx = np.random.choice(len(train), int(1 * len(train)), replace=False)\n",
    "test_idx = np.setdiff1d(np.arange(len(train)), train_idx)\n",
    "\n",
    "train_images = train['jpeg_bytes'].values[train_idx]\n",
    "train_tabular = tabular_scaled[train_idx]\n",
    "train_y = y_train_scaled[train_idx]\n",
    "\n",
    "test_images = test['jpeg_bytes'].values\n",
    "test_tabular = test_tabular_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(\n",
    "    train_images,\n",
    "    train_tabular,\n",
    "    train_y,\n",
    "    TRAIN_TRANSFORMS\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=0#psutil.cpu_count(),\n",
    ")\n",
    "\n",
    "test_dataset = TrainDataset(\n",
    "    test['jpeg_bytes'].values,\n",
    "    test_tabular,\n",
    "    test['id'].values,\n",
    "    TEST_TRANSFORMS,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0#psutil.cpu_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhang\\AppData\\Local\\Temp\\ipykernel_30944\\3017083315.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(weight_path).backbone\n"
     ]
    }
   ],
   "source": [
    "img_backbone = ImageBackbone('swin_large_patch4_window12_384.ms_in22k_ft_in1k', './finetuned_test_model.pth', 384, fixed_feature_extractor=True)\n",
    "tab_backbone = TabularBackbone(n_features=tabular_scaled.shape[1], out_features=128)\n",
    "\n",
    "model = Model(img_backbone, tab_backbone, CONFIG.N_TARGETS)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = torchmetrics.regression.MeanAbsoluteError().to(device)\n",
    "R2 = torchmetrics.regression.R2Score(num_outputs=CONFIG.N_TARGETS, multioutput='uniform_average').to(device)\n",
    "LOSS = AverageMeter()\n",
    "\n",
    "Y_MEAN = torch.tensor(y_train).mean(dim=0).to(device)\n",
    "EPS = torch.tensor([1e-6]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_FN = nn.SmoothL1Loss()  # r2_loss\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    params=model.parameters(),\n",
    "    lr=CONFIG.LR_MAX,\n",
    "    weight_decay=CONFIG.WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "LR_SCHEDULER = get_lr_scheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training:\n",
      "EPOCH 01, 3627/3842 | loss: 0.1613, mae: 0.4283, r2: 0.6170, step: 0.654s, lr: 9.90e-055"
     ]
    }
   ],
   "source": [
    "print(\"Start Training:\")\n",
    "for epoch in range(CONFIG.N_EPOCHS):\n",
    "    MAE.reset()\n",
    "    R2.reset()\n",
    "    LOSS.reset()\n",
    "    model.train()\n",
    "\n",
    "    for step, (X_image, X_tabular, y_true) in enumerate(train_dataloader):\n",
    "        X_image = X_image.to(device)\n",
    "        X_tabular = X_tabular.to(device)\n",
    "        y_true = y_true.to(device)\n",
    "        model = model.to(device)\n",
    "        t_start = time.perf_counter_ns()\n",
    "        y_pred = model(X_image, X_tabular)\n",
    "        loss = LOSS_FN(y_pred, y_true)\n",
    "        LOSS.update(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # xm.optimizer_step(optimizer, barrier=True)\n",
    "        optimizer.zero_grad()\n",
    "        LR_SCHEDULER.step()\n",
    "        MAE.update(y_pred, y_true)\n",
    "        R2.update(y_pred, y_true)\n",
    "\n",
    "        print(\n",
    "            f'\\rEPOCH {epoch + 1:02d}, {step + 1:04d}/{CONFIG.N_STEPS_PER_EPOCH} | ' +\n",
    "            f'loss: {LOSS.avg:.4f}, mae: {MAE.compute().item():.4f}, r2: {R2.compute().item():.4f}, ' +\n",
    "            f'step: {(time.perf_counter_ns() - t_start) * 1e-9:.3f}s, lr: {LR_SCHEDULER.get_last_lr()[0]:.2e}',\n",
    "            end='\\n' if (step + 1) == CONFIG.N_STEPS_PER_EPOCH else '', flush=True,\n",
    "        )\n",
    "    model = model.to(device)\n",
    "\n",
    "    # save model\n",
    "    torch.save(model.to('cpu').state_dict(), './test_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a424ec6174e40dca6403ddbb69bf97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6391 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submit!\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "SUBMISSION_ROWS = []\n",
    "model.eval()\n",
    "\n",
    "for X_image, X_tabular, test_id in tqdm(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_image.to(device), X_tabular.to(device)).detach().cpu().numpy()\n",
    "    \n",
    "    y_pred = Y_SCALER.inverse_transform(y_pred).squeeze()\n",
    "    row = {'id': int(test_id)}\n",
    "    \n",
    "    for k, v in zip(CONFIG.TARGET_COLUMNS, y_pred):\n",
    "        if k in LOG_FEATURES:\n",
    "            row[k.replace('_mean', '')] = 10 ** v\n",
    "        else:\n",
    "            row[k.replace('_mean', '')] = v\n",
    "\n",
    "    SUBMISSION_ROWS.append(row)\n",
    "    \n",
    "submission_df = pd.DataFrame(SUBMISSION_ROWS)\n",
    "submission_df.to_csv('./submission.csv', index=False)\n",
    "print(\"Submit!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
